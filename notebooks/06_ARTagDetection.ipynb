{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb3cf41",
   "metadata": {},
   "source": [
    "# **Task: Using the Drone's front camera, detect an AR tag, identify the Tag ID, then compute the drone's pose from the AR tag's information**\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Use a program to extract the AR tag and convert to a matrix to find the TAG ID\n",
    "2. Corrospond the AR tag to known location values in a pre-determined index\n",
    "3. Using the points of the AR tag, output the drone's pose in a 6 dimensional vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae0a61",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb3e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import cv2.aruco as aruco\n",
    "import os\n",
    "import glob\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b0ff5",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "**Use a program to extract the AR tag to find the tag ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8162019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.12.0\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [87] on image: ARTags/id87.png\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [93] on image: ARTags/image5.png\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [95] on image: ARTags/id95.png\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [95] on image: ARTags/id95_2.png\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [95] on image: ARTags/image3.png\n",
      "<class 'NoneType'>\n",
      "No markers found for image: ARTags/image.png\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [93] on image: ARTags/image6.png\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [87] on image: ARTags/id87_2.png\n",
      "<class 'numpy.ndarray'>\n",
      "Detected ID: [93] on image: ARTags/id93_1.png\n",
      "<class 'NoneType'>\n",
      "No markers found for image: ARTags/id87_1.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(cv2\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m imagepaths:\n\u001b[0;32m----> 7\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n\u001b[1;32m     10\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     12\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mconvertScaleAbs(gray, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folderpath = \"ARTags/\"\n",
    "imagepaths = glob.glob(os.path.join(folderpath, \"*.png\"))\n",
    "kernel = np.ones((3, 3),np.uint8)\n",
    "print(cv2.__version__)\n",
    "\n",
    "for path in imagepaths:\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    image = cv2.convertScaleAbs(gray, alpha=1.0, beta=-50)\n",
    "    image = cv2.erode(image, kernel)\n",
    "\n",
    "\n",
    "    aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_5X5_100)\n",
    "\n",
    "    detectorParams = aruco.DetectorParameters()\n",
    "    detectorParams.aprilTagCriticalRad = 0.1 #default 0.17\n",
    "    detectorParams.aprilTagMaxLineFitMse = 100 #default 10\n",
    "    detectorParams.aprilTagMaxNmaxima = 15 #default 10\n",
    "    detectorParams.polygonalApproxAccuracyRate = 0.01 #default 0.03\n",
    "    detectorParams.useAruco3Detection = True\n",
    "    detector = aruco.ArucoDetector(aruco_dict, detectorParams)\n",
    "    corners, ids, rejected = detector.detectMarkers(gray)\n",
    "\n",
    "    if ids is not None: \n",
    "\n",
    "        print(f\"Detected ID: {ids.flatten()} on image: {path}\")\n",
    "        image = aruco.drawDetectedMarkers(image, corners, ids)\n",
    "    else:\n",
    "        print(f\"No markers found for image: {path}\")\n",
    "        # fig, ax = plt.subplots()\n",
    "        # ax.imshow(image, cmap='gray')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a079c9c",
   "metadata": {},
   "source": [
    "# Step 2 \n",
    "**Corrospond the AR tag to a predetermined location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226ee1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bcb6291",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "**Find the drone's position relative to the tag's position**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e657013",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKER_LENGTH = 0.2667 #Meters\n",
    "CAMERA_MATRIX = np.array([])\n",
    "DIST_COEFFS = []\n",
    "\n",
    "def rotationMatrixToEulerAngles(R):\n",
    "\n",
    "    sy = np.linalg.norm([R[0, 0], R[1, 0]])\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if not singular:\n",
    "        x = np.arctan2(R[2, 1], R[2, 2])  \n",
    "        y = np.arctan2(-R[2, 0], sy)      \n",
    "        z = np.arctan2(R[1, 0], R[0, 0])  \n",
    "    else:\n",
    "        x = np.arctan2(-R[1, 2], R[1, 1])\n",
    "        y = np.arctan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "\n",
    "def func(corners):\n",
    "\n",
    "    rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(corners, MARKER_LENGTH, CAMERA_MATRIX, DIST_COEFFS)\n",
    "\n",
    "    R_marker_to_cam, _ = cv2.Rodrigues(rvecs)\n",
    "\n",
    "    R_cam_to_marker = R_marker_to_cam.T\n",
    "\n",
    "    t_cam_to_marker = -R_cam_to_marker @ tvecs #The position of the camera in the marker's coordinate frame\n",
    "\n",
    "    rvec_cam_to_marker, _ = cv2.Rodrigues(R_cam_to_marker) #The rotation of the camera in relation to the marker (in marker frame)\n",
    "\n",
    "    x, y, z = rotationMatrixToEulerAngles(R_cam_to_marker) #Roll, pitch, yaw\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451b9f1",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "\n",
    "**Write the ros node**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "import cv2\n",
    "from std_msgs.msg import String\n",
    "from std_msgs.msg import Int32\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import cv2.aruco as aruco\n",
    "import sys\n",
    "\n",
    "CAR_TAG_ID = 96\n",
    "CAR_MARKER_LENGTH = 0 #TBD -- Meters\n",
    "MARKER_LENGTH = 0.2667 #Meters\n",
    "CAMERA_MATRIX = np.array([])\n",
    "DIST_COEFFS = ()\n",
    "KERNEL = np.ones((5, 5),np.uint8)\n",
    "\n",
    "class ARTagDetector(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('artag_detector')\n",
    "        self.get_logger().info('ARTag Detector has been initialized')\n",
    "        \n",
    "        #Create camera subscription, 50 milli second wait\n",
    "        self.camera_sub = self.create_subscription(\n",
    "            Image,\n",
    "            '/world/line_following_track/model/x500_mono_cam_down_0/link/camera_link/sensor/imager/image',\n",
    "            self.camera_sub_cb,\n",
    "            50\n",
    "        )\n",
    "\n",
    "        self.tagid_pub = self.create_publisher(String, '/', 1)\n",
    "        self.position_pub = self.create_publisher(Int32, '/line/detector_image', 1)\n",
    "        self.bridge = CvBridge()\n",
    "\n",
    "    \"\"\"\n",
    "    camera callback\n",
    "    Publishes to tag id and position pub\n",
    "    \n",
    "    \"\"\"\n",
    "    def camera_sub_cb(self, msg):\n",
    "        # Convert Image msg to OpenCV image\n",
    "        image = self.bridge.imgmsg_to_cv2(msg, \"mono8\")\n",
    "\n",
    "        # Detect line in the image. detect returns a parameterize the line (if one exists)\n",
    "        tagids, corners = self.detect_id(image)\n",
    "        if tagids is None:\n",
    "            self.get_logger().info('No ARTag found!')\n",
    "        elif np.isin(tagids, CAR_TAG_ID):\n",
    "            self.get_logger().info(f\"Car ARTag Detected! Awaiting response from car...\")\n",
    "            #To be implemented\n",
    "        else:\n",
    "            self.get_logger().info(f'ARTag Detected! Detected: {tagids.flatten()}')\n",
    "\n",
    "        #Rotate to Euler angles\n",
    "        def rotationMatrixToEulerAngles(R):\n",
    "            sy = np.linalg.norm([R[0, 0], R[1, 0]])\n",
    "            singular = sy < 1e-6\n",
    "\n",
    "            if not singular:\n",
    "                x = np.arctan2(R[2, 1], R[2, 2])  \n",
    "                y = np.arctan2(-R[2, 0], sy)      \n",
    "                z = np.arctan2(R[1, 0], R[0, 0])  \n",
    "            else:\n",
    "                x = np.arctan2(-R[1, 2], R[1, 1])\n",
    "                y = np.arctan2(-R[2, 0], sy)\n",
    "                z = 0\n",
    "            return np.array([x, y, z])\n",
    "\n",
    "        # Aruco Estimate pose\n",
    "        rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(corners, MARKER_LENGTH, CAMERA_MATRIX, DIST_COEFFS)\n",
    "\n",
    "        #Turn Rotation to world frame\n",
    "        R_marker_to_cam, _ = cv2.Rodrigues(rvecs)\n",
    "        R_cam_to_marker = R_marker_to_cam.T\n",
    "        #Turn translation to world frame\n",
    "        t_cam_to_marker = -R_cam_to_marker @ tvecs #The position of the camera in the marker's coordinate frame\n",
    "        rvec_cam_to_marker, _ = cv2.Rodrigues(R_cam_to_marker) #The rotation of the camera in relation to the marker (in marker frame)\n",
    "        x, y, z = rotationMatrixToEulerAngles(rvec_cam_to_marker) #Roll, pitch, yaw\n",
    "\n",
    "        #Make ID msg(Remove if not needed)\n",
    "        idmsg = String()\n",
    "        idmsg.data = ' '.join(tagids.flatten().tolist())\n",
    "\n",
    "        #Make position msg where x, y, z are the distance of the camera compared to the marker\n",
    "        # rz is roll, ry is pitch, rz is yaw, published for debugging or other purposes\n",
    "        msg = Int32()\n",
    "        msg.x, msg.y, msg.z = t_cam_to_marker\n",
    "        msg.rx, msg.ry, msg.rz = x, y, z\n",
    "\n",
    "        # Publish\n",
    "        self.tagid_pub.publish(idmsg)\n",
    "        self.position_pub.publish(msg)\n",
    "    \n",
    "    \"\"\"\n",
    "    Function Description: Passing in a grayscale cv2 image and detects the AR tag based on the aruco 5x5 dictionary\n",
    "    with numbers 1-100 (WARNING: IF TAG NOT FULLY VISIBLE AS SQUARE WILL NOT WORK)\n",
    "\n",
    "    Input: Cv2 Image\n",
    "    Output: numpy array of TAGIDs (may be multiple)\n",
    "    \"\"\"\n",
    "    def detect_id(self, image):\n",
    "        image = cv2.convertScaleAbs(gray, alpha=1.0, beta=-50)\n",
    "        image = cv2.erode(image, kernel)\n",
    "\n",
    "\n",
    "        aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_5X5_100)\n",
    "\n",
    "        detectorParams = aruco.DetectorParameters()\n",
    "        detectorParams.aprilTagCriticalRad = 0.1 #default 0.17\n",
    "        detectorParams.aprilTagMaxLineFitMse = 100 #default 10\n",
    "        detectorParams.aprilTagMaxNmaxima = 15 #default 10\n",
    "        detectorParams.polygonalApproxAccuracyRate = 0.01 #default 0.03\n",
    "        detectorParams.useAruco3Detection = True\n",
    "        detector = aruco.ArucoDetector(aruco_dict, detectorParams)\n",
    "        corners, ids, rejected = detector.detectMarkers(gray)\n",
    "\n",
    "        return ids.flatten(), corners\n",
    "\n",
    "def main(args=None):\n",
    "    rclpy.init(args=args)\n",
    "    detector = ARTagDetector()\n",
    "    detector.get_logger.info('ARTag detector initialized')\n",
    "    try:\n",
    "        rclpy.spin(detector)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"ARTag detector shutting down\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "    finally:\n",
    "        detector.destroy_node()\n",
    "        rclpy.shutdown()\n",
    "\n",
    "\n",
    "if __name__=='__main__':#Unneeded if you only ever run the node directly with ros2 run \n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
